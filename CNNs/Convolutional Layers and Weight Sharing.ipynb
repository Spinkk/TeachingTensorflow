{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5d74882",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Spinkk/TeachingTensorflow/blob/main/CNNs/Convolutional%20Layers%20and%20Weight%20Sharing.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7002d50",
   "metadata": {},
   "source": [
    "# Fully Connected Layers vs Convolutional Layers\n",
    "\n",
    "By playing around with the interactive widgets, you've seen how convolutional layers transform input matrices and you've tested different settings involving different padding, kernel sizes, striding, number of filters and number of input channels. In this notebook we will look at how a convolutional layer differs from dense layers and how and in which aspects they share the same properties. We will find that convolutional layers can be thought of as generalizations of dense layers in that they allow for spatial weight sharing across the input.\n",
    "\n",
    "First, let's see that a Conv2D layer can be reduced to a fully connected (dense) layer if the kernel size matches the input size, the strides are (1,1) and no padding is applied (i.e. padding=\"valid\"). Such a convolutional layer can produce the same output as a dense layer if we use the same weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa36188b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b10d260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:cpu:0'):\n",
    "    \n",
    "    \n",
    "    input_shape = (16,16)\n",
    "    n_outputs = 128\n",
    "    \n",
    "    #create input of shape (1,16,16,1)\n",
    "    input_img= tf.random.uniform(shape=(1, input_shape[0], input_shape[1],1))\n",
    "    \n",
    "    # instantiate Conv2D layer with 128 filters with kernel size (16,16), without extra padding\n",
    "    convlayer = tf.keras.layers.Conv2D(filters=n_outputs, \n",
    "                                       kernel_size=input_shape, \n",
    "                                       strides=(1, 1), \n",
    "                                       padding=\"valid\")\n",
    "    \n",
    "    # instantiate dense layer with 128 outputs\n",
    "    denselayer= tf.keras.layers.Dense(n_outputs)\n",
    "    \n",
    "    # flatten input to process it with dense layer\n",
    "    flatted_input = tf.keras.layers.Flatten()(input_img)\n",
    "    denseoutput = denselayer(flatted_input)\n",
    "    \n",
    "    # process input with convlayer\n",
    "    convoutput = convlayer(input_img)\n",
    "    \n",
    "    # reshape weights from dense layer into shape of conv layer weights such that we can use the same weights for both\n",
    "    dense_weights = tf.reshape(denselayer.weights[0], \n",
    "           shape = convlayer.weights[0].shape)\n",
    "    \n",
    "    dense_bias = tf.reshape(denselayer.weights[1],\n",
    "                           shape= convlayer.weights[1].shape)\n",
    "    \n",
    "    # assign weights from dense layer to conv layer to show they result in the same output\n",
    "    convlayer.weights[0].assign(dense_weights)\n",
    "    convlayer.weights[1].assign(dense_bias)\n",
    "    \n",
    "    \n",
    "    convoutput = convlayer(input_img)\n",
    "    \n",
    "    convoutput = tf.reshape(convoutput, shape = denseoutput.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "175173b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv layer has 32768 weights\n",
      "Dense layer has 32768 weights \n",
      "\n",
      "\n",
      "Conv layer has same weights as the dense layer: True\n",
      "Same output for convolutional and dense layer: True\n"
     ]
    }
   ],
   "source": [
    "tf.print(\"Conv layer has\", tf.size(convlayer.weights[0]),\"weights\")\n",
    "\n",
    "tf.print(\"Dense layer has\", tf.size(denselayer.weights[0]),\"weights\",\"\\n\\n\")\n",
    "\n",
    "print(\"Conv layer has same weights as the dense layer:\", tf.reduce_all(convlayer.weights[0] == tf.reshape(\n",
    "    denselayer.weights[0], shape = convlayer.weights[0].shape)).numpy())\n",
    "\n",
    "print(\"Same output for convolutional and dense layer:\", tf.reduce_all(convoutput == denseoutput).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5c4677",
   "metadata": {},
   "source": [
    "We showed that indeed convolutional layers can perform the exact same calculation done in a fully connected layer, leading to the same output given that the parameters are set to the same values. However, convolutional layers can do more than that if we use filter kernels that are smaller than the image, which we will discuss below."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad19f452",
   "metadata": {},
   "source": [
    "# Convolutional layers for spatial weight sharing\n",
    "\n",
    "In last week's lecture content we mentioned that one way to regularize our ANNs is to make use of shared weights. In this notebook, we did not make use of that. Instead we used a large filter kernel to emulate a dense layer. To visualize this, take another look at [the interactive widget](https://Spinkk.github.io/singlekernel_nopadding.html) and set the kernel size to equal the input shape. \n",
    "\n",
    "![image1](fullyconnectedConv.jpg)\n",
    "\n",
    "If however we use a kernel size that is smaller than the input size, we can see that the same weights are used for different locations in the input. This means we can do more with less parameters, having fewer parameters without losing the model's expressivity.\n",
    "\n",
    "![image2](weightssharedConv.jpg)\n",
    "\n",
    "Can you think of reasons why such weight sharing in CNNs may help with overfitting? Does this still hold if we decide to scale up the number of filters and convolutional layers?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:uni] *",
   "language": "python",
   "name": "conda-env-uni-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
